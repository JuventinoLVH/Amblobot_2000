{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *`LIBRETA 2: preparación de los datos para el entrenamiento`*\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta libreta es generar un archivo apto para que el modelo sea entrenado.\n",
    "Dicho de manera poco formal, se usará el resultado de la *libreta 1* para generar las entradas de la *libreta 3* \n",
    "\n",
    "Se pretende que la libreta nos ayude a generar intuiciones en como explorar los datos y como procesar los datos.\n",
    "\n",
    "Durante toda la libreta se usará **Matplotlib** en su *filosofía orientada a objetos*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Linea para ignorar los warnins, en su mayoria son respecto a operaciones con arreglos vacios.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from nltk.lm.preprocessing import flatten\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analisys(EDA)**\n",
    "---\n",
    "Usualmente, hay que transformar la información para que sea más entendible por la máquina, A esto se le llama **preprocesamiento**. El EDA siempre inicia con un vistazo rápido a lo datos. Evidentemente lo primero es poder guardar el corpus en alguna variable de Python. \n",
    "\n",
    "Para esta tarea se ha creado una función que lee la información para del archivo 'conferencias_matutinas_matutinas_amlo(2018)', el cual es una muestra del texto en 'conferencias_matutinas_matutinas_amlo'. \n",
    "\n",
    "Con la filealidad de dejar el corpus lo más *'crudo'* posible se ha tomado cada **renglón** como una **sentencia** con un solo **token**, la sentencia en sí. Esto no es óptimo pues una sentencia debe de ser un listado de tokens que en su conjunto forman una sola *idea*, lo cual no está garantizado en el formato del *corpus crudo*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentencias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buenas tardes.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sí. Es que son buenos días, pero llegué tarde,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y hoy nos acompañó la jefa de gobierno de la C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lo mismo del programa de protección, de apoyo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mañana, les adelanto, se van a dar a conocer e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentencias\n",
       "0                                   Buenas tardes.\\n\n",
       "1  Sí. Es que son buenos días, pero llegué tarde,...\n",
       "2  Y hoy nos acompañó la jefa de gobierno de la C...\n",
       "3  Lo mismo del programa de protección, de apoyo,...\n",
       "4  Mañana, les adelanto, se van a dar a conocer e..."
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Leer_corpus(path,nrows=-1):\n",
    "    corpus_raw\t= pd.DataFrame(columns=['sentencias'])\n",
    "    if nrows > 0 :\n",
    "        with open(path,'r',encoding=\"utf-8\") as frame:\n",
    "            contador = 0;\n",
    "            for linea in frame:\n",
    "                if contador == nrows :\n",
    "                    break\n",
    "                auxiliar = pd.DataFrame( [linea],columns=['sentencias'])\n",
    "                corpus_raw = pd.concat( [corpus_raw, auxiliar ] ,ignore_index=True)\n",
    "                contador=contador+1\t\t\t\t\t\n",
    "    else:\n",
    "        with open(path,'r',encoding=\"utf-8\") as frame:\n",
    "            for linea in frame:\n",
    "                auxiliar = pd.DataFrame( [linea],columns=['sentencias'])\n",
    "                corpus_raw = pd.concat( [corpus_raw, auxiliar ] ,ignore_index=True)\n",
    "    return corpus_raw\n",
    "\n",
    "path =\"./conferencias_matutinas_amlo.txt\"\n",
    "corpus_crudo = Leer_corpus(path,8000)\n",
    "\n",
    "corpus_crudo.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprosesamiento \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['si', 'es', 'que', 'son', 'buenos', 'dias', 'pero', 'llegue', 'tarde', 'porque', 'estabamos', 'tratando', 'temas', 'importantes', 'desde', 'luego', 'el', 'tema', 'de', 'la', 'seguridad'], ['proteccion', 'de', 'apoyo', 'de', 'buen', 'trato', 'de', 'evitar', '<UNK>', '<UNK>', 'a', 'nuestros', 'paisanos', 'que', 'en', 'este', 'mes', 'empiezan', 'a', 'llegar', 'a', 'los', 'pueblos', '<UNK>', 'de', 'estados', 'unidos', 'y', 'que', 'deben', 'de', 'ser'], ['a', 'dar', 'a', 'conocer', 'estos', 'programas', 'que', 'son', 'importantes', 'ya', 'en', 'esta', 'temporada', 'va', 'a', 'participar', 'la', 'policia', 'federal', 'va', 'a', 'participar', 'la', 'secretaria', 'de', 'gobernacion', 'a', 'traves', 'de', 'migracion', 'y', 'aduanas', 'porque', 'tenemos', 'que', 'evitar', 'la', 'extorsion'], ['pero', 'eso', 'es', 'un', 'adelanto', 'mañana', 'vamos', 'a', '<UNK>', 'sobre', 'las', 'acciones'], ['estoy', 'a', 'las', 'ordenes', 'de', 'ustedes'], ['nosotros', 'estamos', 'terminando', 'de', 'integrar', 'lo', 'que', 'corresponde', 'al', 'presupuesto', 'del', 'poder', 'ejecutivo', 'y', 'se', 'estan', 'recibiendo', 'las', 'propuestas', 'de', 'los', 'otros', 'poderes', 'y', 'de', 'organismos', 'autonomos'], ['nosotros', 'no', 'podemos', 'modificar', 'el', 'presupuesto', 'que', 'envia', 'el', 'poder', 'legislativo', 'ni', 'el', 'poder', 'judicial', 'ya', 'se', 'tiene', 'la', 'propuesta', 'del', 'poder', 'legislativo', 'con', 'un', 'plan', 'de', 'austeridad', 'de', 'acuerdo', 'a', 'la'], ['en', 'el', 'caso', 'del', 'poder', 'judicial', 'han', 'presentado', 'tambien', 'su', 'presupuesto', 'se', 'va', 'a', 'entregar', 'a', 'la', 'camara', 'de', 'diputados'], ['y', 'tanto', 'el', 'presupuesto', 'del', 'ejecutivo', 'el', 'presupuesto', 'del', 'legislativo', 'el', 'presupuesto', 'del', 'poder', 'judicial', 'lo', '<UNK>', 'la', 'camara', 'de', 'diputados', 'es', 'la', 'facultad', 'exclusiva', 'de', 'la', 'camara', 'de', 'diputados'], ['toda', 'la', 'informacion', 'los', 'lineamientos', 'generales', 'para', 'la', 'ley', 'de', 'ingresos', 'como', 'vamos', 'a', 'obtener', 'los', 'recursos', 'para', 'financiar', 'el', 'gasto', 'por', 'eso', 'es', 'importante', 'la', 'aprobacion', 'de', 'la', 'ley', 'de', 'ingresos', 'y', 'tambien'], ['en', 'particular', 'el', 'financiamiento', 'para', 'la', 'comision', 'federal', 'de', 'electricidad', 'ya', 'se', 'tiene', 'contemplado', 'va', 'a', 'aumentar', 'la', 'inversion', 'publica', 'tanto', 'en', 'pemex', 'como', 'en', 'la', 'comision', 'federal', 'de', 'electricidad', 'porque', '<UNK>', 'lo', 'hemos', 'venido', 'diciendo', 'producir', 'petroleo', '<UNK>', 'el', 'petroleo', 'para', 'no'], ['ayer', 'dimos', 'a', 'conocer', 'el', 'plan', 'de', 'rehabilitacion', 'de', 'las', 'seis', 'refinerias', 'y', 'de', 'la', 'construccion', 'de', 'una', 'nueva', 'refineria'], ['entonces', 'cual', 'es', 'el', 'plan', 'del', 'nuevo', 'gobierno', 'buscar', 'mas', 'produccion', 'petrolera', '<UNK>', 'y', 'producir', 'los', 'combustibles', 'que', '<UNK>'], ['en', 'el', 'caso', 'de', 'la', 'industria', 'electrica', 'lo', 'mismo', 'eramos', '<UNK>', 'antes', 'del', 'periodo', 'neoliberal', 'y', 'ahora', 'estamos', 'comprando', 'la', 'mitad', 'de', 'la', 'energia', 'electrica', 'que', '<UNK>', 'a', 'precios', '<UNK>'], ['cual', 'es', 'el', 'plan', 'es', 'producir', 'energia', 'electrica', 'sobre', 'todo', 'limpia', 'por', 'eso', 'la', 'rehabilitacion', 'de', 'las', 'hidroelectricas', 'para', 'producir', 'mas', 'energia', 'limpia', 'y', 'es', 'la', 'energia', 'ademas', 'mas', 'barata'], ['por', 'eso', 'el', 'fin', 'de', 'semana', 'estuvimos', 'en', '<UNK>', 'en', 'el', 'municipio', 'de', '<UNK>', 'en', 'el', 'estado', 'de', 'chiapas', 'y', 'ayer', 'en', 'dos', 'bocas', 'paraiso', 'tabasco'], ['proximo', 'en', 'ciudad', 'del', '<UNK>', 'campeche', 'porque', 'vamos', 'a', 'dar', 'a', 'conocer', 'el', 'plan', 'para', 'producir', 'mas', 'petroleo', 'en', 'tierra', 'en', 'el', 'sureste', 'en', 'aguas', 'someras', 'del', 'litoral', 'de', 'tabasco', 'y', 'en', 'la', '<UNK>', 'de', 'campeche', 'pero', 'eso', 'es'], ['no', 'fue', 'un', 'cambio', 'de', 'gobierno', 'es', 'un', 'cambio', 'de', 'regimen', 'antes', 'el', 'poder', 'de', 'los', 'poderes', 'era', 'el', 'ejecutivo', 'se', 'hacia', 'lo', 'que', '<UNK>', 'el', 'presidente', 'no', 'habia', 'estado', 'de'], ['ahora', 'estamos', '<UNK>', 'a', 'que', '<UNK>', 'un', 'autentico', 'estado', 'de', 'derecho', 'que', 'no', 'exista', 'un', 'poder', 'que', '<UNK>', 'a', 'otros', 'poderes', 'eso', 'es', 'lo', 'que', 'esta', 'sucediendo'], ['y', 'no', 'sucede', 'esto', 'en', 'otros', 'paises', 'son', 'los', 'funcionarios', 'publicos', 'mejor', 'pagados', 'en', 'el', 'mundo'], ['<UNK>', 'o', 'integrantes', 'del', 'poder', 'judicial', 'para', 'no', 'generalizar', 'y', '<UNK>', 'a', 'recursos', 'legales', 'amparos', 'estan', 'en', 'su', 'derecho', 'y', 'nosotros', 'vamos', 'a', 'respetar', 'las', 'decisiones', 'que', 'tomen', 'jueces', '<UNK>', 'ministros', 'porque', 'queremos'], ['la', 'facultad', 'exclusiva', 'es', 'de', 'la', 'camara', 'de', 'diputados', 'por', 'eso', 'todavia', 'no', 'esta', 'resuelto', 'este', 'asunto', 'quienes', 'van', 'a', 'decidir', 'va', 'a', 'ser', 'los', 'diputados', 'en', 'el', 'congreso', 'lo', 'que', 'se', 'resuelva', 'en'], ['y', 'aprovecho', 'tambien', 'porque', 'seguramente', 'tambien', 'me', 'lo', 'van', 'a', 'preguntar', 'ya', 'lo', 'dije', 'ayer', 'vamos', 'a', 'respetar', 'la', 'decision', 'del', 'tribunal', 'electoral', 'sobre', 'la', 'eleccion', 'en', 'puebla'], ['porque', 'ya', 'tambien', 'basta', 'de', 'los', '<UNK>', '<UNK>', 'desde', 'luego', 'que', 'como', 'ciudadano', 'pueden', 'decir', 'es', 'que', 'usted', 'es', 'el', 'presidente', 'de', 'mexico', 'usted', 'es', 'el', 'titular', 'del'], ['creo', 'que', 'fue', 'una', 'decision', '<UNK>', '<UNK>', 'lo', 'tengo', 'que', 'decir', 'porque', '<UNK>', 'de', 'un', 'movimiento', 'en', 'donde', 'siempre', 'enfrentamos', 'fraudes', 'electorales', 'y', 'nunca', 'dejamos', 'de', '<UNK>', 'estas', 'practicas', 'antidemocraticas'], ['decision', 'que', 'tomo', 'el', 'tribunal', 'electoral', 'un', 'tribunal', 'que', 'por', 'cierto', 'se', 'integro', 'en', 'lo', 'que', 'yo', 'llamo', 'y', 'cada', 'vez', 'se', 'da', 'conocer', 'espero', 'mas', 'como', 'el', 'viejo', 'regimen', 'con', 'las'], ['saben', 'como', 'se', '<UNK>', 'estos', 'organos', 'no', 'se', 'ponian', 'de', 'acuerdo', 'en', 'el', 'congreso', 'es', 'la', '<UNK>', '<UNK>', '<UNK>', 'de', 'respetar', 'la', 'constitucion', 'y', 'las', 'leyes', 'en', 'la', 'forma', 'para', '<UNK>', 'en', 'el', 'fondo'], ['cargos', 'tres', 'para', 'ti', 'tres', 'para', 'mi', 'y', 'uno', 'si', 'eran', 'siete', 'para', 'los', '<UNK>', 'los', '<UNK>', 'y', 'asi', 'se', '<UNK>', '<UNK>', 'a', '<UNK>', 'a', 'todos', 'venia', 'la'], ['para', 'la', 'integracion', 'de', 'este', 'tribunal', 'o', 'del', 'ine', 'que', 'al', 'final', 'de', 'cuentas', 'era', 'lo', 'mismo', 'estaba', 'yo', 'en', 'una', 'gira', 'en', 'veracruz', 'iban', 'a', '<UNK>', 'el', 'fin', 'de', 'semana', 'y', 'era', 'como', 'el', 'dia', 'de', 'hoy', 'lunes', 'o', 'martes', 'y', 'me', 'adelante', 'y', 'hay', 'constancia', 'porque', 'hasta', 'lo', 'puse', 'en', 'mi', 'face', 'y', 'dije', 'va', 'a', 'quedar', 'asi', 'tres'], ['entonces', 'eso', 'hay', 'que', '<UNK>', 'esas', 'practicas', 'antidemocraticas', 'porque', 'generan', 'mucho', 'daño', 'a', 'las', 'instituciones']]\n",
      "[['<UNK>', '<UNK>'], ['Sí', 'Es', 'que', 'son', 'buenos', 'días', 'pero', '<UNK>', 'tarde', 'porque', 'estábamos', 'tratando', 'temas', 'importantes', 'desde', 'luego', 'el', 'tema', 'de', 'la', 'seguridad'], ['Y', 'hoy', 'nos', 'acompañó', 'la', 'jefa', 'de', 'gobierno', 'de', 'la', 'Ciudad', 'de', 'México', 'estuvo', 'en', 'la', 'reunión', 'del', 'gabinete', 'de', 'seguridad', 'Y', 'también', 'se', 'atendió', 'el', 'Programa', 'de', 'Protección', 'a', '<UNK>', 'porque', 'ya', 'estamos', 'en', 'la', '<UNK>', 'del', 'día', '12', 'y', 'vienen', '<UNK>', 'del', 'país', 'por', 'las', 'carreteras', 'Y', 'se', 'habló', 'del', 'programa', 'de', 'protección'], ['Lo', 'mismo', 'del', 'programa', 'de', 'protección', 'de', 'apoyo', 'de', 'buen', 'trato', 'de', 'evitar', 'extorsiones', '<UNK>', 'a', 'nuestros', 'paisanos', 'que', 'en', 'este', 'mes', 'empiezan', 'a', 'llegar', 'a', 'los', 'pueblos', '<UNK>', 'de', 'Estados', 'Unidos', 'y', 'que', 'deben', 'de', 'ser', 'respetados', 'deben', 'de', 'tener', 'protección', 'apoyo'], ['Mañana', 'les', 'adelanto', 'se', 'van', 'a', 'dar', 'a', 'conocer', 'estos', 'programas', 'que', 'son', 'importantes', 'ya', 'en', 'esta', 'temporada', 'Va', 'a', 'participar', 'la', 'Policía', 'Federal', 'va', 'a', 'participar', 'la', 'Secretaría', 'de', 'Gobernación', 'a', 'través', 'de', 'migración', 'y', 'aduanas', 'porque', 'tenemos', 'que', 'evitar', 'la', 'extorsión', 'en', 'las', 'aduanas', 'a', 'nuestros', 'paisanos'], ['Pero', 'eso', 'es', 'un', 'adelanto', 'Mañana', 'vamos', 'a', 'precisar', 'sobre', 'las', 'acciones'], ['Estoy', 'a', 'las', 'órdenes', 'de', 'ustedes'], ['Estamos', 'por', 'enviar', 'el', 'presupuesto', 'Esta', 'semana', 'se', 'va', 'a', 'llevar', 'a', 'cabo', 'esa', 'acción', 'legal', 'de', 'presentar', 'al', 'Congreso', 'de', 'manera', 'especial', 'a', 'la', 'Cámara', 'de', 'Diputados', 'el', 'presupuesto', 'para', 'el', '2019', 'La', 'Cámara', 'de', 'Diputados', 'es', 'la', 'encargada', 'de', '<UNK>'], ['Nosotros', 'estamos', 'terminando', 'de', 'integrar', 'lo', 'que', 'corresponde', 'al', 'presupuesto', 'del', 'Poder', 'Ejecutivo', 'y', 'se', 'están', 'recibiendo', 'las', 'propuestas', 'de', 'los', 'otros', 'Poderes', 'y', 'de', 'organismos', 'autónomos'], ['De', 'acuerdo', 'a', 'la', 'ley', 'nosotros', 'no', 'podemos', 'modificar', 'el', 'presupuesto', 'que', 'envía', 'el', 'Poder', 'Legislativo', 'ni', 'el', 'Poder', 'Judicial', 'Ya', 'se', 'tiene', 'la', 'propuesta', 'del', 'Poder', 'Legislativo', 'con', 'un', 'plan', 'de', 'austeridad', 'de', 'acuerdo', 'a', 'la', 'política', 'que', 'se', 'va', 'a', 'aplicar'], ['En', 'el', 'caso', 'del', 'Poder', 'Judicial', 'han', 'presentado', 'también', 'su', 'presupuesto', 'se', 'va', 'a', 'entregar', 'a', 'la', 'Cámara', 'de', 'Diputados'], ['Y', 'tanto', 'el', 'presupuesto', 'del', 'Ejecutivo', 'el', 'presupuesto', 'del', 'Legislativo', 'el', 'presupuesto', 'del', 'Poder', 'Judicial', 'lo', 'autoriza', 'la', 'Cámara', 'de', 'Diputados', 'Es', 'la', 'facultad', 'exclusiva', 'de', 'la', 'Cámara', 'de', 'Diputados'], ['Nosotros', 'vamos', 'a', 'cumplir', 'entregando', 'toda', 'la', 'información', 'los', 'lineamientos', 'generales', 'para', 'la', 'Ley', 'de', 'Ingresos', 'cómo', 'vamos', 'a', 'obtener', 'los', 'recursos', 'para', 'financiar', 'el', 'gasto', 'Por', 'eso', 'es', 'importante', 'la', 'aprobación', 'de', 'la', 'Ley', 'de', 'Ingresos', 'y', 'también', 'el', 'presupuesto', 'para', 'el', 'año', 'próximo'], ['Tenemos', 'hasta', 'el', '15', 'hasta', 'finales', 'de', 'esta', 'semana', 'como', 'plazo', 'legal', 'Y', 'vamos', 'a', 'cumplir'], ['El', 'financiamiento', 'del', 'sector', 'energético', 'en', 'particular', 'el', 'financiamiento', 'para', 'la', 'Comisión', 'Federal', 'de', 'Electricidad', 'ya', 'se', 'tiene', 'contemplado', 'Va', 'a', 'aumentar', 'la', 'inversión', 'pública', 'tanto', 'en', 'PEMEX', 'como', 'en', 'la', 'Comisión', 'Federal', 'de', 'Electricidad', 'porque', '<UNK>', 'lo', 'hemos', 'venido', 'diciendo', 'producir', 'petróleo', 'refinar', 'el', 'petróleo', 'para', 'no', 'comprar', 'tanta', 'gasolina', 'en', 'el', 'extranjero'], ['Ayer', 'dimos', 'a', 'conocer', 'el', 'Plan', 'de', '<UNK>', 'de', 'las', 'seis', 'refinerías', 'y', 'de', 'la', 'construcción', 'de', 'una', 'nueva', 'refinería'], ['Y', 'daba', 'yo', 'como', 'datos', 'el', 'que', 'en', 'China', 'en', 'Estados', 'Unidos', 'en', 'Colombia', 'producen', 'los', 'combustibles', 'que', 'consumen', 'Casi', 'el', '100', 'por', 'ciento', 'de', 'los', 'combustibles', 'que', 'consumen', 'los', 'producen', 'Pero', 'también', 'daba', 'el', 'ejemplo', 'de', 'España', 'y', 'de', 'Japón', 'que', 'no', 'tienen', 'petróleo', 'y', 'producen', 'los', 'combustibles', 'que', 'consumen'], ['Nuestro', 'país', 'por', 'el', 'mal', 'gobierno', 'por', 'el', 'fracaso', 'de', 'la', 'llamada', 'política', 'energética', 'tenemos', 'petróleo', 'y', 'estamos', 'comprando', 'el', '75', 'por', 'ciento', 'de', 'las', 'gasolinas', 'que', 'consumimos'], ['Entonces', 'cuál', 'es', 'el', 'plan', 'del', 'nuevo', 'gobierno', 'Buscar', 'más', 'producción', 'petrolera', 'refinar', 'y', 'producir', 'los', 'combustibles', 'que', 'consumimos'], ['En', 'el', 'caso', 'de', 'la', 'industria', 'eléctrica', 'lo', 'mismo', '<UNK>', 'autosuficientes', 'antes', 'del', 'periodo', 'neoliberal', 'y', 'ahora', 'estamos', 'comprando', 'la', 'mitad', 'de', 'la', 'energía', 'eléctrica', 'que', 'consumimos', 'a', 'precios', 'elevadísimos'], ['Cuál', 'es', 'el', 'plan', 'Es', 'producir', 'energía', 'eléctrica', 'sobre', 'todo', 'limpia', 'Por', 'eso', 'la', 'rehabilitación', 'de', 'las', 'hidroeléctricas', 'para', 'producir', 'más', 'energía', 'limpia', 'y', 'es', 'la', 'energía', 'además', 'más', 'barata'], ['Hay', '60', 'hidroeléctricas', 'que', 'no', 'están', 'produciendo', 'a', 'toda', 'su', 'capacidad', 'y', 'en', 'el', 'periodo', 'neoliberal', 'inclusive', 'las', '<UNK>', 'o', 'las', '<UNK>', 'no', '<UNK>', 'toda', 'la', 'energía', 'no', 'trabajaban', 'a', 'toda', 'su', 'capacidad', 'no', '<UNK>', 'para', 'darle', 'preferencia', 'a', 'las', 'empresas', 'que', 'le', 'venden', 'energía', 'eléctrica', 'a', 'la', 'Comisión', 'Federal', 'de', 'Electricidad'], ['Todo', 'eso', 'va', 'a', 'cambiar', 'Por', 'eso', 'el', 'fin', 'de', 'semana', 'estuvimos', 'en', 'Malpaso', 'en', 'el', '<UNK>', 'de', '<UNK>', 'en', 'el', 'Estado', 'de', 'Chiapas', 'y', 'ayer', 'en', 'Dos', 'Bocas', 'Paraíso', 'Tabasco', 'para', 'iniciar', 'los', 'planes', 'de', 'energía'], ['Vamos', 'a', 'estar', 'el', 'sábado', 'próximo', 'en', 'Ciudad', 'del', 'Carmen', 'Campeche', 'porque', 'vamos', 'a', 'dar', 'a', 'conocer', 'el', 'plan', 'para', 'producir', 'más', 'petróleo', 'en', 'tierra', 'en', 'el', 'sureste', 'en', 'aguas', 'someras', 'del', 'litoral', 'de', 'Tabasco', 'y', 'en', 'la', 'Sonda', 'de', 'Campeche', 'Pero', 'eso', 'es', 'el', 'sábado', 'con', 'el', 'mismo', 'propósito'], ['Estamos', 'en', 'una', 'etapa', 'nueva', 'No', 'fue', 'un', 'cambio', 'de', 'gobierno', 'es', 'un', 'cambio', 'de', 'régimen', 'Antes', 'el', 'poder', 'de', 'los', 'poderes', 'era', 'el', 'Ejecutivo', 'se', 'hacía', 'lo', 'que', '<UNK>', 'el', 'Presidente', 'No', 'había', 'Estado', 'de', 'Derecho', 'era', 'un', 'Estado', 'de', 'chueco'], ['Ahora', 'estamos', 'comprometidos', 'a', 'que', 'funcione', 'un', 'auténtico', 'Estado', 'de', 'Derecho', 'que', 'no', 'exista', 'un', 'poder', 'que', '<UNK>', 'a', 'otros', 'poderes', 'Eso', 'es', 'lo', 'que', 'está', 'sucediendo'], ['Nosotros', 'decidimos', 'de', 'conformidad', 'con', 'la', 'ley', 'promover', 'la', 'reducción', 'de', 'los', 'salarios', 'de', 'los', 'altos', 'funcionarios', 'públicos', 'porque', 'son', 'salarios', '<UNK>', 'Son', '<UNK>', 'los', 'salarios', 'de', 'los', 'altos', 'funcionarios', 'públicos', 'en', 'el', 'país', 'y', 'de', 'manera', 'particular', 'en', 'el', 'Poder', 'Judicial', 'llegan', 'a', 'reunir', 'hasta', '600', 'mil', 'pesos', 'mensuales', 'Eso', 'es', 'ofensivo', 'Eso', 'no', 'tiene', 'que', 'ver', 'ni', 'con', 'el', 'cambio', 'que', 'se', 'necesita', 'y', 'que', 'está', 'demandando', 'la', 'gente', 'ni', 'con', 'la', 'justicia', 'Al', 'contrario', 'Es', 'una', 'arbitrariedad'], ['Y', 'no', 'sucede', 'esto', 'en', 'otros', 'países', 'Son', 'los', 'funcionarios', 'públicos', 'mejor', 'pagados', 'en', 'el', 'mundo'], ['<UNK>', 'que', 'tenía', 'que', 'cumplirse', 'la', 'Constitución', 'el', 'artículo', '127', 'esto', 'fue', 'aprobado', 'también', 'por', 'el', 'Poder', 'Legislativo'], ['Entonces', 'el', 'Poder', 'Judicial', 'se', '<UNK>', 'o', 'integrantes', 'del', 'Poder', 'Judicial', 'para', 'no', 'generalizar', 'y', '<UNK>', 'a', 'recursos', 'legales', 'amparos', 'Están', 'en', 'su', 'derecho', 'Y', 'nosotros', 'vamos', 'a', 'respetar', 'las', 'decisiones', 'que', 'tomen', 'jueces', 'magistrados', 'ministros', 'porque', 'queremos', 'que', 'haya', 'un', 'estado', 'de', 'derecho']]\n",
      "[['buenas', '<UNK>'], ['si', 'es', 'que', 'son', 'buenos', 'dias', 'pero', 'llegue', 'tarde', 'porque', 'estabamos', 'tratando', 'temas', 'importantes', 'desde', 'luego', 'el', 'tema', 'de', 'la', 'seguridad'], ['y', 'hoy', 'nos', 'acompaño', 'la', 'jefa', 'de', 'gobierno', 'de', 'la', 'ciudad', 'de', 'mexico', 'estuvo', 'en', 'la', 'reunion', 'del', 'gabinete', 'de', 'seguridad', 'y', 'tambien', 'se', 'atendio', 'el', 'programa', 'de', 'proteccion', 'a', '<UNK>', 'porque', 'ya', 'estamos', 'en', 'la', '<UNK>', 'del', 'dia', '<DGT>', 'y', 'vienen', '<UNK>', 'del', 'pais', 'por', 'las', 'carreteras', 'y', 'se', 'hablo', 'del', 'programa', 'de', 'proteccion'], ['lo', 'mismo', 'del', 'programa', 'de', 'proteccion', 'de', 'apoyo', 'de', 'buen', 'trato', 'de', 'evitar', '<UNK>', '<UNK>', 'a', 'nuestros', 'paisanos', 'que', 'en', 'este', 'mes', 'empiezan', 'a', 'llegar', 'a', 'los', 'pueblos', '<UNK>', 'de', 'estados', 'unidos', 'y', 'que', 'deben', 'de', 'ser', 'respetados', 'deben', 'de', 'tener', 'proteccion', 'apoyo'], ['mañana', 'les', 'adelanto', 'se', 'van', 'a', 'dar', 'a', 'conocer', 'estos', 'programas', 'que', 'son', 'importantes', 'ya', 'en', 'esta', 'temporada', 'va', 'a', 'participar', 'la', 'policia', 'federal', 'va', 'a', 'participar', 'la', 'secretaria', 'de', 'gobernacion', 'a', 'traves', 'de', 'migracion', 'y', 'aduanas', 'porque', 'tenemos', 'que', 'evitar', 'la', 'extorsion', 'en', 'las', 'aduanas', 'a', 'nuestros', 'paisanos'], ['pero', 'eso', 'es', 'un', 'adelanto', 'mañana', 'vamos', 'a', 'precisar', 'sobre', 'las', 'acciones'], ['estoy', 'a', 'las', 'ordenes', 'de', 'ustedes'], ['estamos', 'por', 'enviar', 'el', 'presupuesto', 'esta', 'semana', 'se', 'va', 'a', 'llevar', 'a', 'cabo', 'esa', 'accion', 'legal', 'de', 'presentar', 'al', 'congreso', 'de', 'manera', 'especial', 'a', 'la', 'camara', 'de', 'diputados', 'el', 'presupuesto', 'para', 'el', '<DGT>', 'la', 'camara', 'de', 'diputados', 'es', 'la', 'encargada', 'de', '<UNK>'], ['nosotros', 'estamos', 'terminando', 'de', 'integrar', 'lo', 'que', 'corresponde', 'al', 'presupuesto', 'del', 'poder', 'ejecutivo', 'y', 'se', 'estan', 'recibiendo', 'las', 'propuestas', 'de', 'los', 'otros', 'poderes', 'y', 'de', 'organismos', 'autonomos'], ['de', 'acuerdo', 'a', 'la', 'ley', 'nosotros', 'no', 'podemos', 'modificar', 'el', 'presupuesto', 'que', 'envia', 'el', 'poder', 'legislativo', 'ni', 'el', 'poder', 'judicial', 'ya', 'se', 'tiene', 'la', 'propuesta', 'del', 'poder', 'legislativo', 'con', 'un', 'plan', 'de', 'austeridad', 'de', 'acuerdo', 'a', 'la', 'politica', 'que', 'se', 'va', 'a', 'aplicar'], ['en', 'el', 'caso', 'del', 'poder', 'judicial', 'han', 'presentado', 'tambien', 'su', 'presupuesto', 'se', 'va', 'a', 'entregar', 'a', 'la', 'camara', 'de', 'diputados'], ['y', 'tanto', 'el', 'presupuesto', 'del', 'ejecutivo', 'el', 'presupuesto', 'del', 'legislativo', 'el', 'presupuesto', 'del', 'poder', 'judicial', 'lo', 'autoriza', 'la', 'camara', 'de', 'diputados', 'es', 'la', 'facultad', 'exclusiva', 'de', 'la', 'camara', 'de', 'diputados'], ['nosotros', 'vamos', 'a', 'cumplir', 'entregando', 'toda', 'la', 'informacion', 'los', 'lineamientos', 'generales', 'para', 'la', 'ley', 'de', 'ingresos', 'como', 'vamos', 'a', 'obtener', 'los', 'recursos', 'para', 'financiar', 'el', 'gasto', 'por', 'eso', 'es', 'importante', 'la', 'aprobacion', 'de', 'la', 'ley', 'de', 'ingresos', 'y', 'tambien', 'el', 'presupuesto', 'para', 'el', 'año', 'proximo'], ['tenemos', 'hasta', 'el', '<DGT>', 'hasta', 'finales', 'de', 'esta', 'semana', 'como', 'plazo', 'legal', 'y', 'vamos', 'a', 'cumplir'], ['el', 'financiamiento', 'del', 'sector', 'energetico', 'en', 'particular', 'el', 'financiamiento', 'para', 'la', 'comision', 'federal', 'de', 'electricidad', 'ya', 'se', 'tiene', 'contemplado', 'va', 'a', 'aumentar', 'la', 'inversion', 'publica', 'tanto', 'en', 'pemex', 'como', 'en', 'la', 'comision', 'federal', 'de', 'electricidad', 'porque', '<UNK>', 'lo', 'hemos', 'venido', 'diciendo', 'producir', 'petroleo', 'refinar', 'el', 'petroleo', 'para', 'no', 'comprar', 'tanta', 'gasolina', 'en', 'el', 'extranjero'], ['ayer', 'dimos', 'a', 'conocer', 'el', 'plan', 'de', 'rehabilitacion', 'de', 'las', 'seis', 'refinerias', 'y', 'de', 'la', 'construccion', 'de', 'una', 'nueva', 'refineria'], ['y', 'daba', 'yo', 'como', 'datos', 'el', 'que', 'en', 'china', 'en', 'estados', 'unidos', 'en', '<UNK>', 'producen', 'los', 'combustibles', 'que', 'consumen', 'casi', 'el', '<DGT>', 'por', 'ciento', 'de', 'los', 'combustibles', 'que', 'consumen', 'los', 'producen', 'pero', 'tambien', 'daba', 'el', 'ejemplo', 'de', 'españa', 'y', 'de', '<UNK>', 'que', 'no', 'tienen', 'petroleo', 'y', 'producen', 'los', 'combustibles', 'que', 'consumen'], ['nuestro', 'pais', 'por', 'el', 'mal', 'gobierno', 'por', 'el', 'fracaso', 'de', 'la', 'llamada', 'politica', 'energetica', 'tenemos', 'petroleo', 'y', 'estamos', 'comprando', 'el', '<DGT>', 'por', 'ciento', 'de', 'las', 'gasolinas', 'que', 'consumimos'], ['entonces', 'cual', 'es', 'el', 'plan', 'del', 'nuevo', 'gobierno', 'buscar', 'mas', 'produccion', 'petrolera', 'refinar', 'y', 'producir', 'los', 'combustibles', 'que', 'consumimos'], ['en', 'el', 'caso', 'de', 'la', 'industria', 'electrica', 'lo', 'mismo', 'eramos', '<UNK>', 'antes', 'del', 'periodo', 'neoliberal', 'y', 'ahora', 'estamos', 'comprando', 'la', 'mitad', 'de', 'la', 'energia', 'electrica', 'que', 'consumimos', 'a', 'precios', 'elevadisimos'], ['cual', 'es', 'el', 'plan', 'es', 'producir', 'energia', 'electrica', 'sobre', 'todo', 'limpia', 'por', 'eso', 'la', 'rehabilitacion', 'de', 'las', 'hidroelectricas', 'para', 'producir', 'mas', 'energia', 'limpia', 'y', 'es', 'la', 'energia', 'ademas', 'mas', 'barata'], ['hay', '<DGT>', 'hidroelectricas', 'que', 'no', 'estan', 'produciendo', 'a', 'toda', 'su', 'capacidad', 'y', 'en', 'el', 'periodo', 'neoliberal', 'inclusive', 'las', '<UNK>', 'o', 'las', '<UNK>', 'no', '<UNK>', 'toda', 'la', 'energia', 'no', 'trabajaban', 'a', 'toda', 'su', 'capacidad', 'no', '<UNK>', 'para', 'darle', 'preferencia', 'a', 'las', 'empresas', 'que', 'le', 'venden', 'energia', 'electrica', 'a', 'la', 'comision', 'federal', 'de', 'electricidad'], ['todo', 'eso', 'va', 'a', 'cambiar', 'por', 'eso', 'el', 'fin', 'de', 'semana', 'estuvimos', 'en', 'malpaso', 'en', 'el', 'municipio', 'de', '<UNK>', 'en', 'el', 'estado', 'de', 'chiapas', 'y', 'ayer', 'en', 'dos', 'bocas', 'paraiso', 'tabasco', 'para', 'iniciar', 'los', 'planes', 'de', 'energia'], ['vamos', 'a', 'estar', 'el', 'sabado', 'proximo', 'en', 'ciudad', 'del', 'carmen', 'campeche', 'porque', 'vamos', 'a', 'dar', 'a', 'conocer', 'el', 'plan', 'para', 'producir', 'mas', 'petroleo', 'en', 'tierra', 'en', 'el', 'sureste', 'en', 'aguas', 'someras', 'del', 'litoral', 'de', 'tabasco', 'y', 'en', 'la', '<UNK>', 'de', 'campeche', 'pero', 'eso', 'es', 'el', 'sabado', 'con', 'el', 'mismo', 'proposito'], ['estamos', 'en', 'una', 'etapa', 'nueva', 'no', 'fue', 'un', 'cambio', 'de', 'gobierno', 'es', 'un', 'cambio', 'de', 'regimen', 'antes', 'el', 'poder', 'de', 'los', 'poderes', 'era', 'el', 'ejecutivo', 'se', 'hacia', 'lo', 'que', '<UNK>', 'el', 'presidente', 'no', 'habia', 'estado', 'de', 'derecho', 'era', 'un', 'estado', 'de', 'chueco'], ['ahora', 'estamos', 'comprometidos', 'a', 'que', 'funcione', 'un', 'autentico', 'estado', 'de', 'derecho', 'que', 'no', 'exista', 'un', 'poder', 'que', '<UNK>', 'a', 'otros', 'poderes', 'eso', 'es', 'lo', 'que', 'esta', 'sucediendo'], ['nosotros', 'decidimos', 'de', 'conformidad', 'con', 'la', 'ley', 'promover', 'la', 'reduccion', 'de', 'los', 'salarios', 'de', 'los', 'altos', 'funcionarios', 'publicos', 'porque', 'son', 'salarios', '<UNK>', 'son', '<UNK>', 'los', 'salarios', 'de', 'los', 'altos', 'funcionarios', 'publicos', 'en', 'el', 'pais', 'y', 'de', 'manera', 'particular', 'en', 'el', 'poder', 'judicial', 'llegan', 'a', 'reunir', 'hasta', '<DGT>', 'mil', 'pesos', 'mensuales', 'eso', 'es', '<UNK>', 'eso', 'no', 'tiene', 'que', 'ver', 'ni', 'con', 'el', 'cambio', 'que', 'se', 'necesita', 'y', 'que', 'esta', 'demandando', 'la', 'gente', 'ni', 'con', 'la', 'justicia', 'al', 'contrario', 'es', 'una', 'arbitrariedad'], ['y', 'no', 'sucede', 'esto', 'en', 'otros', 'paises', 'son', 'los', 'funcionarios', 'publicos', 'mejor', 'pagados', 'en', 'el', 'mundo'], ['<UNK>', 'que', 'tenia', 'que', '<UNK>', 'la', 'constitucion', 'el', 'articulo', '<DGT>', 'esto', 'fue', 'aprobado', 'tambien', 'por', 'el', 'poder', 'legislativo'], ['entonces', 'el', 'poder', 'judicial', 'se', '<UNK>', 'o', 'integrantes', 'del', 'poder', 'judicial', 'para', 'no', 'generalizar', 'y', '<UNK>', 'a', 'recursos', 'legales', 'amparos', 'estan', 'en', 'su', 'derecho', 'y', 'nosotros', 'vamos', 'a', 'respetar', 'las', 'decisiones', 'que', 'tomen', 'jueces', 'magistrados', 'ministros', 'porque', 'queremos', 'que', 'haya', 'un', 'estado', 'de', 'derecho']]\n"
     ]
    }
   ],
   "source": [
    "#Procesamiento que modifica todo lo que se nos pudo ocurrir. Se busca cualquier excusa minimamente \n",
    "# coherente para eliminar \n",
    "def todo_UNK(sentencia):\n",
    "        for palabra in sentencia:\n",
    "            if(palabra != '<UNK>'):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "def Procesamiento_invasivo (corpus):\n",
    "\n",
    "    # <- Una lista de listas(sublistas). Cada sublistas tiene solo un elemento.\n",
    "    corpus_preprocesado = corpus_crudo.values.tolist()     \n",
    "\n",
    "    #Se eliminan las sentencias que tengan numero. \n",
    "    corpus_preprocesado = [ sentencia if (re.search(r'\\d+',sentencia[0]) == None) else []   \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "\n",
    "\n",
    "    #Se transforma a lista de listas y se aplica el lower\n",
    "    # NOTA: el lower tambien funiona para palabras con acentos \n",
    "    corpus_preprocesado = [ re.sub(r'\\W',' ',sentencia[0]).lower()  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "\n",
    "\n",
    "    #Se quitan los acentos\n",
    "    vocales = (\n",
    "        ('á' , 'a'),\n",
    "        ('é', 'e'),\n",
    "        ('í' , 'i'),\n",
    "        ('ó' , 'o'),\n",
    "        ('ú' , 'u')\n",
    "    )\n",
    "    for vocales_acentuadas,vocales_regulares in vocales:\n",
    "        corpus_preprocesado = [ sentencia.replace(vocales_acentuadas,vocales_regulares) \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "        \n",
    "\n",
    "    #Se separan las letras \n",
    "    corpus_preprocesado = [ sentencia.split()  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "\n",
    "\n",
    "\n",
    "    #Se Omiten las sentencias que tengan 2 o menos palabras\n",
    "    #   Se aprovecha para remover tambien las sentencias que en primera intancia no tenian nada\n",
    "    corpus_preprocesado = [ (sentencia if len(sentencia) >= 3 else [])   \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #A las sentencias muy largas se les quita algunas palabras del inicio y otras del fileal\n",
    "    # Puede que este procesamiento no tenga mucho sentido. es mas un ejercicio de regex \n",
    "    # que algo ultil\n",
    "    corpus_preprocesado = [ (sentencia if len(sentencia) <= 35 else sentencia[5:-6])   \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    \n",
    "    \n",
    "    #Para los siguientes preprocesamientos, se calcula la frecuencia de cada palabra\n",
    "    palabras_frecuentes = Counter(flatten(corpus_preprocesado))\n",
    "\n",
    "        \n",
    "    #Se cambian las palabras poco frecuentes en el corpus\n",
    "    #   Para quitar los n elementos menos frecuentes es frecuencias.most_frecuens()[ : -1 - n , -1 ]\n",
    "    for index in range(len(corpus_preprocesado)):\n",
    "        corpus_preprocesado[index] = [ palabra if \n",
    "                        palabras_frecuentes[palabra] > 3\n",
    "                        else '<UNK>'  \n",
    "                        for palabra in corpus_preprocesado[index]]\n",
    "    \n",
    "    #Si una sentencia tiene puras palabras UNK, se elimina\n",
    "    corpus_preprocesado = [  sentencia if not todo_UNK(sentencia) else []  for sentencia in corpus_preprocesado]    \n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "    \n",
    "    return corpus_preprocesado\n",
    "#file Procesamiento intrusivo --------------------------------------------------------------------------------------\n",
    "\n",
    "#Preprosesamiento Preprosesamiento pensado para hacer lo que pienso personalmente mas correcto\n",
    "def Procesamiento_prudente (corpus):\n",
    "\n",
    "    # <- Una lista de listas(sublistas). Cada sublistas tiene solo un elemento.\n",
    "    corpus_preprocesado = corpus_crudo.values.tolist()     \n",
    "\n",
    "\n",
    "\n",
    "    #Se transforma a lista de listas y se aplica el lower\n",
    "    # NOTA: el lower tambien funiona para palabras con acentos \n",
    "    corpus_preprocesado = [ re.sub(r'\\W',' ',sentencia[0]).lower()  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "\n",
    "    #Cambiamos los numeros por un token\n",
    "    corpus_preprocesado = [ re.sub(r'\\d+','<DGT>',sentencia)  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    \n",
    "\n",
    "    #Se quitan los acentos\n",
    "    vocales = (\n",
    "        ('á' , 'a'),\n",
    "        ('é', 'e'),\n",
    "        ('í' , 'i'),\n",
    "        ('ó' , 'o'),\n",
    "        ('ú' , 'u')\n",
    "    )\n",
    "    for vocales_acentuadas,vocales_regulares in vocales:\n",
    "        corpus_preprocesado = [ sentencia.replace(vocales_acentuadas,vocales_regulares) \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "        \n",
    "\n",
    "    #Se separan las letras \n",
    "    corpus_preprocesado = [ sentencia.split()  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "\n",
    "\n",
    "\n",
    "    #Se Omiten las sentencias que tengan 2 o menos palabras\n",
    "    #   Se aprovecha para remover tambien las sentencias que en primera intancia no tenian nada\n",
    "    corpus_preprocesado = [ (sentencia if len(sentencia) >= 1 else [])   \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Para los siguientes preprocesamientos, se calcula la frecuencia de cada palabra\n",
    "    palabras_frecuentes = Counter(flatten(corpus_preprocesado))\n",
    "    #Se cambian las palabras poco frecuentes en el corpus\n",
    "    #   Para quitar los n elementos menos frecuentes es frecuencias.most_frecuens()[ : -1 - n , -1 ]\n",
    "    for index in range(len(corpus_preprocesado)):\n",
    "        corpus_preprocesado[index] = [ palabra if \n",
    "                        palabras_frecuentes[palabra] > 2\n",
    "                        else '<UNK>'  \n",
    "                        for palabra in corpus_preprocesado[index]]\n",
    "    \n",
    "    #Si una sentencia tiene puras palabras UNK, se elimina\n",
    "    corpus_preprocesado = [  sentencia if not todo_UNK(sentencia) else []  for sentencia in corpus_preprocesado]    \n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]\n",
    "    \n",
    "    return corpus_preprocesado\n",
    "#file preprosesamiento prudente ---------------------------------------------------------------\n",
    "    \n",
    "\n",
    "#Procesamiento destinado a hacer el minimo procesamiento\n",
    "def Procesamiento_simple(corpus):\n",
    "\n",
    "    # <- Una lista de listas(sublistas). Cada sublistas tiene solo un elemento.\n",
    "    corpus_preprocesado = corpus_crudo.values.tolist()     \n",
    "\n",
    "\n",
    "    #Se transforma a lista de listas y se aplica el lower\n",
    "    # NOTA: el lower tambien funiona para palabras con acentos \n",
    "    corpus_preprocesado = [ re.sub(r'\\W',' ',sentencia[0])  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    \n",
    "    \n",
    "    #Se separan las letras y se eliminan los sentencas vacias\n",
    "    corpus_preprocesado = [ sentencia.split()  \n",
    "                           for sentencia in corpus_preprocesado]\n",
    "    corpus_preprocesado = [ sentencia for sentencia in corpus_preprocesado if sentencia != []]    \n",
    "\n",
    "    \n",
    "    #Se cambian las palabras poco frecuentes en el corpus por el token <UNK>\n",
    "    palabras_frecuentes = Counter(flatten(corpus_preprocesado))\n",
    "    for index in range(len(corpus_preprocesado)):\n",
    "        corpus_preprocesado[index] = [ palabra if \n",
    "                        palabras_frecuentes[palabra] > 1\n",
    "                        else '<UNK>'  \n",
    "                        for palabra in corpus_preprocesado[index]]\n",
    "\n",
    "    return corpus_preprocesado\n",
    "# file preprosesamiento simple ------------------------------------------------------------\n",
    "\n",
    "corpus_procesamiento_prudente= Procesamiento_prudente(corpus_crudo)\n",
    "corpus_procesamiento_simple = Procesamiento_simple(corpus_crudo)\n",
    "corpus_procesamiento_invasivo = Procesamiento_invasivo(corpus_crudo)\n",
    "\n",
    "print((corpus_procesamiento_invasivo[:30]))\n",
    "print((corpus_procesamiento_simple[:30]))\n",
    "print((corpus_procesamiento_prudente[:30]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo: EDA\n",
    "--- \n",
    "EDA nos permite visualizar la información para hacer nuestros propios descubrimientos (*insights* en inglés). La probabilidad de hacer descubrimientos es proporcional a la capacidad que se tenga para visualizar la información. \n",
    "\n",
    "Nuestro objetivo es preprocesar las sentencias de diferentes maneras y aplicar un EDA sobre cada uno de estos **corpus procesados**. Al fileal escogeremos la que más creamos pertinente y lo llamaremos **corpus ordenado**. El *corpus procesado* se asume que cada  elemento es una *sentencia*, a su vez cada sentencia es un conjunto de *tokens*.\n",
    "\n",
    "La filealidad del objeto *EDA_* es ser una recopilación de herramientas para al fileal poder tener distintas métricas con las cuales comparar los derivados que se llega a hacer del corpus crudo.\n",
    "\n",
    "---\n",
    "*EDA_PLN* Contiene herramientas para hacer 'exploratory data analisys'\n",
    "\n",
    "*   dataframe: El corpus sobre el cual se efectuara el EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA_PLN():\n",
    "\t\n",
    "\t#El objeto obtiene el corpus en el formato lista de listas [ ['token' , 'token' ... 'token'] , ['token',token ...] , ...]\n",
    "\tdef __init__(self,corpus) -> None:\n",
    "\t\tself.corpus\t= corpus\n",
    "\t\tself.corpus_unidimensional = []\n",
    "\t\tfor sentencia in self.corpus:\n",
    "\t\t\tfor token in sentencia:\n",
    "\t\t\t\tself.corpus_unidimensional.append(token)\n",
    "\n",
    "\t#Toma el corpus y regresa la frecuencia de los n_grama\n",
    "\t#\tSolo agrupa las oraciones, no añade tokens de fin e inicio de sentencia\n",
    "\tdef get_top_ngram(self, n_grams=1):\n",
    "\t\tgramas = (ngrams(self.corpus_unidimensional,n_grams))\n",
    "\t\tfrecuencias = FreqDist( gramas  )\n",
    "\t\treturn frecuencias.most_common(10)\n",
    "\n",
    "\n",
    "\t#Grafica un histograma con la cantidad de palabras en cada sentencia\n",
    "\tdef Palabras_por_sentencia(self,\n",
    "\t\t\t    eje = None,\n",
    "\t\t\t    tamano_titulo = 18,\n",
    "\t\t\t    tamano_ejes = 10,\n",
    "\t\t\t    titulo=\"Histograma de longitud por sentencias\"):\n",
    "\t\tif eje is None:\t\n",
    "\t\t\tpresentacion ,eje = plt.subplots(1)\n",
    "\n",
    "\n",
    "\t\teje.hist( list(map( lambda x : len(x)  , self.corpus )) )\n",
    "\t\t\n",
    "\t\teje.set_title(titulo, fontsize = tamano_titulo)\n",
    "\t\teje.set_ylabel(\"Frecuencia\", fontsize = tamano_ejes)\n",
    "\t\teje.set_xlabel(\"Longitud\",fontsize = tamano_ejes)\t\n",
    "\n",
    "\t#No funciona\n",
    "\tdef Longitud_promedio_de_palabras(self,\n",
    "\t\t\t    eje = None):\n",
    "\t\tpass\n",
    "\n",
    "\t#No funciona\n",
    "\tdef Palabras_mas_comunes(self,\n",
    "\t\t\t  \tstopwords = {''},\n",
    "\t\t\t    eje = None):\n",
    "\t\tpass\n",
    "\n",
    "\t#No funciona\n",
    "\tdef Palabras_menos_comunes(self,\n",
    "\t\t\t  \tstopwords,\n",
    "\t\t\t    eje = None):\n",
    "\t\tpass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EDA_PLN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m EDA_tokenizado_por_palabra \u001b[39m=\u001b[39m EDA_PLN(corpus_crudo[\u001b[39m'\u001b[39m\u001b[39msentencias\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit())\n\u001b[0;32m      2\u001b[0m EDA_corpus_crudo \u001b[39m=\u001b[39m EDA_PLN(corpus_crudo\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m      4\u001b[0m stop\u001b[39m=\u001b[39m\u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39mspanish\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EDA_PLN' is not defined"
     ]
    }
   ],
   "source": [
    "EDA_tokenizado_por_palabra = EDA_PLN(corpus_crudo['sentencias'].str.split())\n",
    "EDA_corpus_crudo = EDA_PLN(corpus_crudo.values.tolist())\n",
    "\n",
    "stop=set(stopwords.words('spanish'))\n",
    "\n",
    "with plt.style.context('bmh'):\n",
    "    EDA_tokenizado_por_palabra.Caracteres_por_sentencia()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preludio al modelo**\n",
    "---\n",
    "Lo ultimo que se hara en la libreta es guardar los corpus y generar los conjuntos de prueba y entrenamiento. La funcion **split_file** es recuperada de: https://github.com/soutsios/n-gram-language-models/blob/master/lang_mod.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_file(file, out1, out2, percentage=0.75, isShuffle=True, seed=764):\n",
    "    \"\"\"Splits a file in 2 given the `percentage` to go in the large file.\"\"\"\n",
    "    random.seed(seed)\n",
    "    with open(file, 'r',encoding=\"utf-8\") as file, \\\n",
    "         open(out1, 'w', encoding=\"utf-8\") as foutBig, \\\n",
    "         open(out2, 'w', encoding=\"utf-8\") as foutSmall:\n",
    "                nLines = sum(1 for line in file)\n",
    "                file.seek(0)\n",
    "                nTrain = int(nLines*percentage) \n",
    "                nValid = nLines - nTrain\n",
    "                i = 0\n",
    "                for line in file:\n",
    "                    r = random.random() if isShuffle else 0 # so that always evaluated to true when not isShuffle\n",
    "                    if (i < nTrain and r < percentage) or (nLines - i > nValid):\n",
    "                        foutBig.write(line)\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        foutSmall.write(line)\n",
    "                    \n",
    "def corpus_procesato_a_csv(corpus,nombre_csv):\n",
    "    corpus_pd = pd.DataFrame({'sentencias' :corpus}  )\n",
    "    corpus_pd.to_csv(nombre_csv , index = False)\n",
    "    split_file(nombre_csv,nombre_csv+'_entrenamiento',nombre_csv+'_prueba')\n",
    "\n",
    "corpus_procesato_a_csv(corpus_procesamiento_simple,\"procesado_simple\")\n",
    "corpus_procesato_a_csv(corpus_procesamiento_prudente,\"procesado_prudente\")\n",
    "corpus_procesato_a_csv(corpus_procesamiento_invasivo,\"procesado_invasivo\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amblobot",
   "language": "python",
   "name": "amblobot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efa26e886de7e46764a101ed13df147086b087aaab571ad83cb1c7970d41a000"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
